---
layout: post
title: "Optimisation dâ€™un script SHELL"
date: 2015-01-27 12:26:40
image: /assets/img/optimisation.png
description: Optimisation dâ€™un script SHELL
category: 'SHELL'
tags:
- administration systÃ¨me
- SHELL
twitter_text: Optimisation dâ€™un script SHELL
introduction: Il faut toujours repasser derriÃ¨re les apprentis !
---

> [image disponible sur WikiCommons](https://commons.wikimedia.org/wiki/File:Second%2Bstage%2Bacceleration%2Bprogram-5(1).png) par [Jeriahkosch](https://commons.wikimedia.org/wiki/User:Jeriahkosch) sous licence [CC-BY-SA-4.0](https://creativecommons.org/licenses/by-sa/4.0/deed.en)

Nous avons un script shell. Celui-ci fonctionne en deux Ã©tapes. La premiÃ¨re Ã©tape dure une nuit. La deuxiÃ¨me Ã©tape dure elle aussi toute une nuit. Cependant, ce processus doit Ãªtre exÃ©cutÃ© pour 60 serveurs. La durÃ©e totale thÃ©orique est donc de 120 jours!

La premiÃ¨re Ã©tape peut Ãªtre parallÃ©lisÃ©e, sur les 60 serveurs en mÃªme temps. La premiÃ¨re Ã©tape peut donc avoir une durÃ©e dâ€™une nuit si on lance le processus sur les 60 serveurs en parallÃ¨le. La deuxiÃ¨me Ã©tape ne peut Ãªtre parallÃ©lisÃ©e car elle doit Ãªtre exÃ©cutÃ©e sur un seul et unique serveur et elle gÃ©nÃ¨re 60 rÃ©sultats diffÃ©rents (un par serveur source, dÃ©pendant du rÃ©sultat de lâ€™Ã©tape 1 exÃ©cutÃ©e sur chacun des serveurs sources). La 2e Ã©tape a donc une durÃ©e incompressible de 60 nuits.

Il faut donc au moins 61 nuits (1 + 60) pour exÃ©cuter lâ€™intÃ©gralitÃ© du processus. Trop long. Trop complexe. Trop peu sÃ»r (on a du relancer le processus plusieurs fois suite Ã  des erreurs). Comment optimiser cela?

Edit : prÃ©cisions apportÃ©es suite au commentaire de Â« bob morane Â», merci Ã  lui!

## Le script

Les principes de base du script sont les suivants :

* rÃ©cupÃ©rer des noms dâ€™image dans une base de donnÃ©es
* gÃ©nÃ©rer une liste de ses images
* regarder sur le systÃ¨me de fichier sâ€™il y a :
  * une image de taille X1 pour ce nom dâ€™image
  * une image de taille X2 pour ce nom dâ€™image
  * une image de taille X3 pour ce nom dâ€™image
  * une image de taille X4 pour ce nom dâ€™image
  * une image de taille X5 pour ce nom dâ€™image
  * vÃ©rifier pour chaque taille si lâ€™image existe en .JPG ou en .jpg
* gÃ©nÃ©rer une liste des images manquantes
* cette liste est ensuite rÃ©cupÃ©rÃ©e par un humain
* elle est copiÃ©e sur un serveur
* les images de cette liste (dâ€™images manquantes) sont ajoutÃ©es dans un tar.gz. Comme on ne sait pas sâ€™il manque une image en .JPG ou une image en .jpg, il est nÃ©cessaire de * vÃ©rifier quel est le bon nom de lâ€™image manquante.

Deux personnes sont passÃ©es sur ce script. Deux jeunes, dÃ©butants. Ce script a Ã©tÃ© une arlÃ©sienne pendant plusieurs mois :

* impossible dâ€™avoir quelque chose de fonctionnel
* des formats ayant Ã©tÃ© oubliÃ©s, il a fallu recommencer les traitements (2 nuits Ã  chaque fois)
* une erreur bÃªte dans le script ayant Ã©tÃ© faite, il a encore fallu recommencer les traitements
* la correction de cette erreur bÃªte nâ€™a Ã©tÃ© faite quâ€™Ã  un seul endroit au lieu de deux, il a encore fallu recommencer les traitements.

Je leur ai parlÃ© dâ€™optimisation. Cela semblait impossible : Ã§a avait lâ€™air dâ€™une complexitÃ© sans nom. Ne pouvait-on pas refaire ce script en quelque chose de plus rapide que le bash? Non. Ne pouvait on pas utiliser des structures de donnÃ©es plus performantes telles les tables de hachage? Non. Ne pouvait-on pas revoir lâ€™ordre des Ã©tapes pour optimiser le processus? Non. Peut-on passer par un find, stocker le rÃ©sultat dans un fichier texte et faire des recherches dans le rÃ©sultat? Non!

AprÃ¨s une Ã©niÃ¨me erreur, jâ€™ai fini par mâ€™y attaquer directement. Jâ€™ai donc ouvert ce script moi-mÃªme, pour regarder le code (je vous invite Ã  regarder Â« Code is lawÂ« ). Ouch! Heureusement que jâ€™Ã©tais seul sinon les insultes auraient plu comme jamais! Ce script Ã©tait une horreur infecte, sans nom, rempli dâ€™erreurs et dâ€™erreurs potentielles, dâ€™approximations, de ralentissements, â€¦ :

* enchaÃ®nement de sed lÃ  oÃ¹ on pouvait nâ€™en faire quâ€™un seul
* Ã  chaque Ã©tape dâ€™une boucle, une variable Ã©tait re-calculÃ©e. Cette variable Ã©tait composÃ©e de deux parties : une partie toujours identique et une partie diffÃ©rente, en fonction de lâ€™itÃ©ration de la boucle. Le calcul de cette premiÃ¨re partie incluait des appels Ã  sed/awk/grep/â€¦ Il Ã©tait possible de faire le calcul avant de rentrer dans la boucle mais Ã§a nâ€™avait pas Ã©tÃ© fait.
* Ã  chaque itÃ©ration de la boucle, une vingtaine dâ€™opÃ©rations de lecture sont faites sur le systÃ¨me de fichier.
* en cas dâ€™erreur, il faut relancer lâ€™intÃ©gralitÃ© du script.
* â€¦

Pendant lâ€™exÃ©cution de ce script, le serveur est fortement ralenti, les utilisateurs se plaignent. Il faut trouver une autre voie.

## Revenir au but premier

Lorsquâ€™on est le nez dans le guidon et complÃ¨tement dÃ©passÃ©, il est nÃ©cessaire de sâ€™arrÃªter. Sâ€™arrÃªter complÃ¨tement. Presque tout jeter Ã  la poubelle, pour revenir au Â« but premierÂ« . Le Â« but premier Â» est lâ€™objectif que lâ€™on doit atteindre. Lorsquâ€™on a un script Ã  rÃ©aliser, le but premier est Â« quel est lâ€™objectif Ã  atteindre pour ce script? Â». Il ne faut pas confondre Â« quel est lâ€™objectif Ã  atteindre? Â» avec Â« quel est le but du script? Â». Ceci sont deux choses diffÃ©rentes :

* lâ€™un se concentre sur lâ€™objectif, le rÃ©sultat final, le fonctionnel.
* lâ€™autre se concentre sur la rÃ©alisation de cet objectif : la partie technique, les tÃ¢ches intermÃ©diaires. Or parfois, Ã©tant parti sur une mauvaise idÃ©e, on reste bloquÃ© dans la rÃ©alisation de cette mauvaise idÃ©e. On reste dans des considÃ©rations techniques, parfaitement inutile car une autre voie existe.

Il faut donc repartir sur lâ€™objectif premier et se demander Â« quâ€™est ce que lâ€™on voulait faire dÃ©jÃ ?Â« . Il y a dâ€™autres situations sur lesquels on peut bloquer et pour lesquels on doit prendre une dÃ©cision. Il faut alors lÃ  aussi revenir au but premier, qui peut Ãªtre totalement diffÃ©rent :

* quel est le but rÃ©el de ce projet? dans le cas dâ€™un problÃ¨me technique bloquant, ne pouvant Ãªtre rÃ©solu rapidement. Parfois, le but du projet ne nÃ©cessite pas que ce problÃ¨me soit rÃ©solu dÃ¨s Ã  prÃ©sent, dans la phase actuelle. Le projet peut Ãªtre re-planifiÃ©, en excluant cette fonction bloquante, le temps que le problÃ¨me technique soit rÃ©solu. Si le projet peut avancer sans cette fonction, pourquoi se priver? Une fois que le problÃ¨me technique est rÃ©solu, il faut rÃ©-intÃ©grer la fonction dans le projet. Ce genre de rÃ©flexion est difficile Ã  accepter car elle implique un Ã©chec, temporaire, mais un Ã©chec. Il ne faut pas se focaliser sur ce pseudo-Ã©chec mais sur lâ€™atteinte de lâ€™objectif global.
* quel est le but de la structure? LÃ , câ€™est encore pire : de nombreux projets rencontrent de nombreux problÃ¨mes, certains sont bloquants, dâ€™autres ont des impacts non nÃ©gligeables sur les autres entitÃ©s de la structure. Bref, toute la structure est impactÃ©e. Ces problÃ¨mes sont liÃ©s Ã  diffÃ©rentes sous-entitÃ©s et, pour elles, son problÃ¨me est trÃ¨s important et trÃ¨s urgent. Il faut prioriser les sujets, mais comment? En se basant sur lâ€™objectif premier de la structure. En se concentrant sur le global et non sur les sous-entitÃ©s ou les personnes. Et Ã©duquer les personnes de ces sous-entitÃ©s pour leur faire accepter que leurs problÃ¨mes ne sont pas prioritaires et quâ€™ils auront plus de travail encore. Pas simpleâ€¦

Le but premier est premier dans le sens oÃ¹ il est le plus important et il est aussi le but original, celui que nous souhaitions atteindre avant que Â« tout se passe mal Â» et que Â« Ã§a parte complÃ¨tement en couilles Â» comme disent les anciens jeunes.

Revenons Ã  notre sujet : que souhaitions nous faire exactement?

## Notre but premier

Notre but premier est le suivant : vÃ©rifier que toutes les images dÃ©clarÃ©es dans une application sont bien prÃ©sentes sur tous les serveurs et pourront Ãªtres affichÃ©es Ã  lâ€™utilisateur, lorsquâ€™il le demande.

OK, on y voir dÃ©jÃ  plus clair. Une nouvelle analyse sâ€™impose. Voici les caractÃ©ristiques :

* lâ€™application et les donnÃ©es sont identiques partout, sur tous les serveurs! La base de donnÃ©es Ã©tant identique partout, elle contient donc les mÃªmes images. Il nâ€™est pas nÃ©cessaire de recalculer sur chaque serveur la liste des images devant Ãªtre prÃ©sente!
* les images peuvent disposer de lâ€™extension .JPG ou .jpg.
* les images doivent Ãªtre prÃ©sentes dans les formats X1, X2, X3, X4 et X5.
* il faut identifier les images manquantes et les renvoyer.
* si on Ã©crase les images? Câ€™est Ã  dire si lâ€™on renvoie des images dÃ©jÃ  prÃ©sentes? Ce nâ€™est pas grave : elles seront identiques alorsâ€¦
* Et si on renvoyait tout? Câ€™est Ã  dire quâ€™on nâ€™exÃ©cute pas le script et que lâ€™on considÃ¨re quâ€™il faut renvoyer lâ€™intÃ©gralitÃ© des images? Non, beaucoup trop lourd, pas assez dâ€™espace sur les serveurs cibles et connexion internet limitÃ©e pour la majoritÃ© des serveurs (quelques MBits/s).

## Optimisons

Une premiÃ¨re optimisation est dÃ©jÃ  faite : on construit un fichier contenant la liste des images devant Ãªtre prÃ©sentes une et une seule fois.

Effectuer 20 opÃ©rations dâ€™accÃ¨s disque pour chaque itÃ©ration de boucle est trop coÃ»teux. Pourquoi ne pas inverser? Un find est fait sur le serveur cible, il liste tous les fichiers prÃ©sents, on stocke Ã§a dans un fichier et ensuite on fait des recherches dans ce fichier. Combien de temps prends le find? AprÃ¨s un test : quelques minutes seulement! De plus, sâ€™il y a une erreur dans le script, on pourra rÃ©aliser ce rÃ©sultat intermÃ©diaire, sans le refaire! Banco!

Ensuite, il faut Ã©viter les fork dans les scripts bash : ceci est trÃ¨s trÃ¨s trÃ¨s coÃ»teux. Demander Ã  Nagios! Il faut donc Ã©viter au maximum les appels aux commandes externes : sed/awk/grep/cut/ls/â€¦ On peut utiliser les builtins commands (les commandes internes Ã  bash qui rÃ©-implÃ©mentent en partie sed/cut/grep/â€¦ et sont plus rapides Ã  utiliser) mais nous ne sommes pas trÃ¨s Ã  lâ€™aise avec celles-ci. DÃ©veloppons dans un autre langage quâ€™un langage interprÃ©tÃ©. Prenons un langage dâ€™administrateur, relativement simple (si bien utilisÃ©) et plus performant. Qui vote pour Java? Bon, Java est Ã©liminÃ© dâ€™emblÃ©e. Bizarre! Quelquâ€™un a parlÃ© de Ruby mais il a Ã©tÃ© abattu de suite, sans sommation. ğŸ˜‰ Reste les vrais langages : Perl et Python. La moitiÃ© (moi) prÃ©fÃ¨re Perl, lâ€™autre moitiÃ© (les deux autres) prÃ©fÃ¨re Python (oui, je compte pour deux ğŸ˜‰ ). Difficile de se dÃ©partager.

Pour optimiser les recherches, rien de mieux quâ€™une table de hachage : on stocke lâ€™intÃ©gralitÃ© du fichier rÃ©sultat du find dans une table de hachage et on fait des recherches en utilisant les clÃ©s. Moi jâ€™ai dÃ©jÃ  utilisÃ© des tables de hachage en Perl : trÃ¨s trÃ¨s rapide. Et vous, en Python? Jamais? Bon, reste Ã  vÃ©rifier que le chargement du fichier et sa mise en table de hachage nâ€™est pas trop long et ne fait pas exploser la mÃ©moire. Je vÃ©rifie, par un script trÃ¨s lÃ©ger, qui ne fait que charger le fichier dâ€™exemple et le transformer en table de hachage. Zut, jâ€™ai du me tromper dans le code : Ã§a sâ€™est terminÃ© beaucoup trop rapidement. OÃ¹ me suis-je trompÃ©? â€¦ Bizarreâ€¦ Heuâ€¦ nonâ€¦ pas dâ€™erreur. En fait, câ€™est hyper-supra-giga-ultra-mÃ©ga-rapide. On part donc sur Perl et les tables de hachage.

Reste la gÃ©nÃ©ration du tar.gz devant contenir les images manquantes. PlutÃ´t que de faire un tar.gz contenant les images manquantes dâ€™un seul serveur, pourquoi ne pas faire un tar.gz contenant toutes les images? Lâ€™idÃ©e est discutÃ©e et adoptÃ©e en considÃ©rant lâ€™option suivante : collecter tous les rÃ©sultats et les analyser pour identifier des Â« pattern Â». Nous identifions :

* sur beaucoup de serveurs, il manque peu dâ€™images (quelques centaines au total)
* sur quelques serveurs, il manque beaucoup dâ€™images et ce sont toujours les mÃªmes images qui sont manquantes.

On a donc fait deux paquets .tar.gz : un agrÃ©geant toutes les images manquantes sur de nombreux serveurs ; lâ€™autre agrÃ©geant le trÃ¨s grand nombre dâ€™images manquantes.

Une derniÃ¨re optimisation a Ã©tÃ© faite pour faire un fichier contenant la liste des images manquantes le plus propre et le plus efficace possible, afin dâ€™amÃ©liorer la construction des tar.gz.

Dâ€™autres optimisations sont faites, elles sont mineures mais ont encore permis dâ€™amÃ©liorer le rÃ©sultat.
# RÃ©sultat

Auparavant :

* 10 heures pour identifier les images manquantes sur 1 serveur : Ã  faire 60 fois
* entre 10 heures et 24 heures pour gÃ©nÃ©rer une archive contenant les images manquantes : Ã  faire 60 fois.

DorÃ©navant :

* 10 minutes (oui, 10 minutes!) pour identifier les images manquantes. Ces actions peuvent Ãªtre faites en parallÃ¨le sur tous les serveurs. Elle peut aussi Ãªtre refait Ã  la demande!!! En effet, lâ€™impact est beaucoup plus lÃ©ger quâ€™auparavant.
* deux fois 6 heures pour gÃ©nÃ©rer une archive contenant les images manquantes.

## Conclusion

Â« tâ€™as essayÃ© de prendre du recul? Â» Vous avez dÃ©jÃ  entendu cela dâ€™un Â« petit chef Â» sans savoir ce quâ€™il voulait dire? Moi oui. Â« Prends du recul Â» nâ€™est pas trÃ¨s parlant, nâ€™aide pas forcÃ©ment. Lorsquâ€™on est dans ce genre de situation, bloquÃ©, il est trÃ¨s compliquÃ© de prendre du recul. En gÃ©nÃ©ral, il faut revenir au but premier et demander de lâ€™aide Ã  un oeil extÃ©rieur : une personne qui nâ€™a pas travaillÃ© sur le sujet mais qui pourrait avoir une autre approche. Cela peut vous aider Ã  trouver une nouvelle voie.
